\section{Optische Handgestenerkennung}
\label{sec:fallstudie}
\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{images/arduino_ex.png}
    \caption{Das Arduino-Board ATmega328P mit 3x3 Matrix von Lichtsensoren in Lego-Verpackung. Illustriert werden die möglichen Handgestentypen mit Ausnahme der Nullgeste.}
    \label{fig:arduino_ex}
\end{figure}
Diese Arbeit ist Teil einer Fallstudie zur Handgestenerkennung auf Low-End Mikro-Controllern von dem Institut für Telematik an der TUHH \cite{venzkeArticle}. Das Ziel ist die Handgestenerkennung in Echtzeit mit so wenig
Resourcen wie möglich, damit die Produktion der einzelnen Module so kostengünstig wie möglich ist. Als Eingabe dient, je nach Modul, eine 3x3, bzw. 4x4, Matrix von Lichtsensoren. Dabei werden 5 Typen von Handgesten
untersucht: Links nach Rechts, Rechts nach Links, Oben nach Unten, Unten nach Oben und NullGeste, i. e. eine invalide Geste (siehe Abbildung \ref{fig:arduino_ex}). Die bisherigen Arbeiten haben sich mit künstlichen
neuronalen Netzen beschäftigt. Dessen Prozessablauf zur Gestenerkennung lässt sich im Grunde auf 3 Schritte zusammenfassen.
\begin{enumerate}
    \item Extrahiere einen Gestenkandidaten.
    \item Vorverarbeite den Gestenkandidaten.
    \item Wende das Model auf die vorverarbeiteten Daten an.
\end{enumerate}

\input{chapter/state_of_the_art/optical_handgesture_recognition/gesture_candidate_extraction}
\input{chapter/state_of_the_art/optical_handgesture_recognition/scaling}
\input{chapter/state_of_the_art/optical_handgesture_recognition/training}
\input{chapter/state_of_the_art/optical_handgesture_recognition/knn}
