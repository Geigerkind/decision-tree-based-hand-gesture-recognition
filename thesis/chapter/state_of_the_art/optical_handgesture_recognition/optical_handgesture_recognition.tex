\section{Optische Handgestenerkennung}
\label{sec:fallstudie}
Diese Arbeit ist Teil einer Fallstudie zur Handgestenerkennung auf Low-End Mikrocontrollern von dem Institut für Telematik an der TUHH \cite{venzkeArticle}. Das Ziel ist die Handgestenerkennung in Echtzeit mit so wenig
Ressourcen wie möglich, damit die Produktion der einzelnen Module so kostengünstig wie möglich ist. Als Eingabe dient, je nach Modul, eine 3x3, bzw. 4x4, Matrix von Lichtsensoren. Abbildung \ref{fig:arduino_ex}
illustriert vier Typen von Handgesten, die durch den Mikrocontroller erkannt werden: Links nach Rechts, Rechts nach Links, Oben nach Unten, Unten nach Oben. Zudem wird zwischen Handgesten und Nullgesten, d. h.
invalide Handgesten, unterschieden. In den bisherigen Arbeiten wurden ML Modelle mit künstlichen neuronalen Netzwerken erstellt. Deren Prozessablauf zur Handgestenerkennung lässt sich mit drei
Schritten zusammenfassen \cite{venzkeArticle}.
\begin{enumerate}
    \item Extrahiere einen Gestenkandidaten.
    \item Vorverarbeite den Gestenkandidaten.
    \item Wende das Modell auf den vorverarbeiteten Gestenkandidaten an.
\end{enumerate}
\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{images/arduino_ex.png}
    \caption{Das Arduino-Board ATmega328P mit 3x3 Matrix von Lichtsensoren in Lego-Verpackung. Illustriert werden die möglichen Handgestentypen mit Ausnahme der Nullgeste.}
    \label{fig:arduino_ex}
\end{figure}

\input{chapter/state_of_the_art/optical_handgesture_recognition/gesture_candidate_extraction}
\input{chapter/state_of_the_art/optical_handgesture_recognition/scaling}
\input{chapter/state_of_the_art/optical_handgesture_recognition/training}
\input{chapter/state_of_the_art/optical_handgesture_recognition/knn}
