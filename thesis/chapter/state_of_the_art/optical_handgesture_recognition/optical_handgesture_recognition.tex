\section{Optische Handgestenerkennung}
\label{sec:fallstudie}
\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{images/arduino_ex.png}
    \caption{Das Arduino-Board ATmega328P mit 3x3 Matrix von Lichtsensoren in Lego-Verpackung. Illustriert werden die möglichen Handgestentypen mit Ausnahme der Nullgeste.}
    \label{fig:arduino_ex}
\end{figure}
Diese Arbeit ist Teil einer Fallstudie zur Handgestenerkennung auf Low-End Mikrocontrollern von dem Institut für Telematik an der TUHH \cite{venzkeArticle}. Das Ziel ist die Handgestenerkennung in Echtzeit mit so wenig
Ressourcen wie möglich, damit die Produktion der einzelnen Module so kostengünstig wie möglich ist. Als Eingabe dient, je nach Modul, eine 3x3, bzw. 4x4, Matrix von Lichtsensoren. Abbildung \ref{fig:arduino_ex}
illustriert 4 Typen von Handgesten, die über den Mikrocontroller ausgeführt werden: Links nach Rechts, Rechts nach Links, Oben nach Unten, Unten nach Oben. Zudem wird zwischen Handgesten und Nullgsten, d. h.
invalide Handgesten. Die bisherigen Arbeiten haben sich mit künstlichen neuronalen Netzen beschäftigt. Dessen Prozessablauf zur Gestenerkennung lässt sich im Grunde auf 3 Schritte zusammenfassen.
\begin{enumerate}
    \item Extrahiere einen Gestenkandidaten.
    \item Vorverarbeite den Gestenkandidaten.
    \item Wende das Modell auf die vorverarbeiteten Gestenkandidaten an.
\end{enumerate}

\input{chapter/state_of_the_art/optical_handgesture_recognition/gesture_candidate_extraction}
\input{chapter/state_of_the_art/optical_handgesture_recognition/scaling}
\input{chapter/state_of_the_art/optical_handgesture_recognition/training}
\input{chapter/state_of_the_art/optical_handgesture_recognition/knn}
