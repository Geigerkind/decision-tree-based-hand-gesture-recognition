\section{Scikit-Learn}
In dieser Arbeit wird die Python ML-Bibliothek \textit{Scikit-Learn} verwendet. Scikit-Learn bietet verschiedene ML Algorithmen mit einem High-Level Interface an \cite{scikit-learn}. Unter anderem konstruiert Scikit-Learn
Entscheidungsbäume mit dem Algorithmus von CART \cite{ScikitLearnCART}. Scikit-Learn kann Klassifizierer (\texttt{DecisionTreeClassifier}) und Regressoren (\texttt{Decision TreeRegressor}) generieren.
\newline
\newline
Relevant für diese Arbeit ist nur der \texttt{DecisionTreeClassifier}. Dieser bietet eine Reihe an Hyperparametern an, um die Konstruktion des Entscheidungsbaumes zu steuern. Verwendet werden \texttt{max\_depth}
und \texttt{min\_samples\_leaf}. Der Hyperparameter \texttt{max\_depth} beschränkt die maximale Baumhöhe und\texttt{min\_samples\_leaf} beschränkt die minimale Blattgröße.
Die Blattgröße ist die kleinste Anzahl von Einträgen, bei der ein Knoten noch geteilt werden darf \cite{ScikitLearnDTC}.
Diese Parameter sind relevant, weil sie die Größe der Entscheidungsbäume beeinflussen. Je größer ein einzelner Entscheidungsbaum ist, desto mehr Speicher
verbraucht er. Das heißt, wenn der Speicher begrenzt ist, kann man weniger Entscheidungsbäume im Ensemble haben.
\newline
\newline
Scikit-Learn implementiert viele Ensemble-Methoden, die in Kombination mit dem Klassifizierer mit Entscheidungsbäumen genutzt werden können. Ihr Interface ist sehr ähnlich.
Alle bieten \texttt{n\_estimators} an, welche die Größe des Ensembles bestimmt, bzw. die Waldgröße. Denn ein Ensemble von Entscheidungsbäumen bildet einen Entscheidungswald \cite{ScikitLearnEnsemble}.