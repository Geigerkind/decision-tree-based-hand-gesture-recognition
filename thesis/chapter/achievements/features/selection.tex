\subsection{Featureauswahl}
\label{sec:feature_selection}
Untersucht wurden die Features aus Tabelle \ref{tab:songFeatures} die von Song et al. genutzt wurden, das Motion History Image und zwei selbst entwickelte Features. Die Features aus
Tabelle \ref{tab:songFeatures} erfüllen ohne Änderungen nicht ausreichend Anforderungen. Die Features 3 und 4 wurden in abgewandelter Form in der Helligkeitsverteilung verwendet.
Die Features 2, 5 und 7 bis 9 wurden nicht getestet, da sie zu komplexe Berechnungen für kleine eingebettete Systeme bedürfen.
\newline
\newline
Das \textit{Mean absolute value} Feature von Song et al. ermöglicht die einzelnen Handgesten zu unterscheiden, wenn das Feature auf verschiedene Zeitfenster dupliziert wird. Zusätzlich kann die Helligkeit
normalisiert werden. Um die Feature-Menge zu verringern, können Spalten und Zeilen zusammengefasst werden. In der Praxis generalisierte der Ansatz aber nicht gut. Es wird vermutet, dass die Varianz sehr groß
ist, wenn die Handgeste mit verschiedenen Geschwindigkeiten ausgeführt wird.
\newline
\newline
\textit{Average amplitude change} von Song et al. eignet sich gut, um horizontale und vertikale Bewegungen zu unterscheiden. Allerdings ist es nicht möglich symmetrische Bewegungen zu unterscheiden, da
die Berechnung unabhängig von der Richtung ist. Dadurch wäre zum Beispiel eine Links nach Rechts Bewegung nicht von einer Rechts nach Links Bewegung zu unterscheiden. Aus diesem Grund wurde dieses Feature nicht
weiter untersucht.

\subsubsection{Motion History}
Das Motion History Feature komprimiert die Bewegung vieler Bilder in ein Bild, indem kürzlich stattgefundene Bewegungen heller erscheinen als länger zurückliegende Bewegungen (Kapitel \ref{sec:sota_misc}). Das
Feature ist invariant gegenüber unterschiedlichen Lichtverhältnissen, solange die Funktion $\psi$ invariant ist, um Bewegungen zu detektieren. Überlappende Bewegungen können nicht dargestellt werden, da die
Historie überschrieben wird. In dieser Arbeit ist das bei den validen Handgesten kein Problem, da diese keine überlappenden Bewegungen beinhalten.
\newline
\newline
Die Aussagekraft des Features ist abhängig von den Parametern $\tau$ und $\delta$. Je nach dem, ist eine Bewegungshistorie nicht sichtbar, wenn $\delta$ zu gering ist oder $\tau$ zu groß, oder ein Teil der
Bewegungshistorie ist abgeschnitten, wenn $\delta$ zu groß ist oder $\tau$ zu klein. Damit die vollständige Handgeste abgebildet wird, ist $\delta$ abhängig von $\tau$ und der Handgestenlänge, d. h.
$\delta = \frac{\tau}{\#Bilder}$.
\newline
\newline
Eine Bewegung in einem Pixel $q$ wird durch die Funktion \ref{formular:motion_history_phi} signalisiert. Die Bewegung in $q$ findet statt, wenn eine absolute Veränderung oberhalb des Durchschnitts der
absoluten Veränderung in der Helligkeit detektiert wird.
\begin{align}
    \phi(q,t) = \begin{cases}
                    1 & if \Delta_{q,t} \geq \frac{1}{N} \sum_{n=1}^N \Delta_{q,n} \\
                    0 & otherwise
    \end{cases}
    \hspace{0.5cm}where\ \Delta_{q,t} = |q_t - q_{t-1}|
    \label{formular:motion_history_phi}
\end{align}

\subsubsection{Helligkeitsverteilung}
Die Helligkeitsverteilung stellt die Pixel mit Extrema in der Helligkeit über Zeitfenster dar. Die Extrema der Helligkeit sind entweder der hellste oder dunkelste Pixel in einem oder mehrerer Bilder. Pixel
sind heller, wenn ihre Werte größer sind und dunkler, wenn ihre Werte geringer sind. Folglich können die Pixel mit den Extrema über die Komposition der Funktionen $\arg$ und $\max$ bzw. $\min$ definiert werden,
d. h. für ein Bild $Q$ ist der hellste Pixel $q' = \arg(\max Q)$ und der dunkelste Pixel $q' = \arg(\min Q)$.
\newline
\newline
Eine Handgeste besteht aus einer Sequenz von Bildern. Diese wird in Zeitfenster unterteilt, sodass möglichst gleich viele Bilder in jedem Zeitfenster enthalten sind. Ist die Anzahl der Bilder nicht ohne
Rest teilbar mit der Anzahl der Zeitfenster, so werden die überschüssigen Bilder uniform auf die Zeitfenster verteilt. Anschließend wird jedes Zeitfenster zusammengefasst. Es gibt mehrere Möglichkeiten
die einzelnen Bilder in einem Zeitfenster zusammenzufassen.
\begin{itemize}
    \item Für jedes Zeitfenster wähle das Maximum bzw. das Minimum aus. Das heißt, jedes Zeitfenster wird von dem Pixel repräsentiert, welches den Maximalen bzw. Minimalen Wert hat.
    \item Projiziere das Frame auf ein kartesisches Koordinatensystem, sodass der untere linke Pixel die Koordinaten $(0,0)$ hat und der obere rechte Pixel $(2,2)$. Wähle aus jeden Frame im
          Zeitfenster den Pixel mit dem maximalen bzw. minimalen Wert aus. Fasse anschließend die Koordinaten der Punkte über eine Abstandsmetrik zusammen, um den Mittelpunkt zu ermitteln. Projiziere
          den Mittelpunkt auf den nächsten diskreten Punkt im Koordinatensystem und gebe ihn als Wert den Durchschnitt der akkumulierten Pixel. Im weiteren Verlauf dieser Arbeit wird dies als geometrische
          Helligkeitsverteilung bezeichnet.
    \item Weise jedem Pixel zu einem oder mehrere Quadranten zu in einem Pixel. Dabei bilden benachbarte Pixel einen Quadranten mit einer maximalen Größe von vier. Für jeden Frame im Zeitfenster
          wird der Pixel mit dem maximalen bzw. minimalen Wert ermittelt. Wähle den Quadranten aus, der die meisten Maxima bzw. Minima beinhaltet.
\end{itemize}
Desweiteren können die Anzahl der Zeitfenster variiert werden und Pixel zu Gruppen zusammgenfasst werden. Das heißt, anstatt jeden Pixel im einzelnen zu betrachten, können Gruppen von Pixeln zueinander
betrachtet werden, z. B. Spalten und Zeilen des Frames. Die evaluierte Helligkeitsverteilung in dieser Arbeit nimmt keine Gruppierung vor. Es werden sechs Zeitfenster extrahiert die geometrisch zusammengefasst
werden.
\newline
\newline
Es wird davon ausgegangen, dass dieses Feature invariant gegenüber unterschiedlichen Lichtverhältnissen ist, da nur relative Helligkeitsunterschiede relevant sind und Kontraste irrelevant bei der
Berechnung sind.

\subsubsection{Schwerpunktverteilung}
\label{sec:schwerpunktverteilung}
Die Schwerpunktverteilung stellt Schwerpunkte über Zeitfenster dar. Der Schwerpunkt $(X_Q, Y_Q)$ in einem Bild $Q$ (Formel \ref{formular:pictureAsFormular}) ist über die Helligkeit der einzelnen
Pixel definiert. Der Pixel $q_{11}$ bildet den Nullpunkt des Koordinatensystems. Dann ist relativ zur Gesamthelligkeit $P = \sum_{i,j} q_{i,j}$, $X_Q=\frac{\sum_{i=0}^{2} q_{i,2} - \sum_{i=0}^{2} q_{i,0}}{P}$
die horizontale Komponente und $Y_Q = \frac{\sum_{i=0}^{2} q_{0,i} - \sum_{i=0}^{2} q_{2,i}}{P}$ die vertikale Komponente des Schwerpunktes \cite{schwerpunktAnsatz}.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{images/schwerpunkt_ansatz.jpg}
    \caption{Illustration des Schwerpunktes im 3x3 Fotowiderstand-Array.}
    \label{fig:schwerpunkt}
\end{figure}
\begin{align}
    Q = \begin{pmatrix}
            q_{00} & q_{01} & q_{02} \\
            q_{10} & q_{11} & q_{12} \\
            q_{20} & q_{21} & q_{22}
    \end{pmatrix}
    \label{formular:pictureAsFormular}
\end{align}
Die Handgeste wird in Zeitfenster aufgeteilt. Jedes Zeitfenster beinhaltet gleich viele Bilder. Sollte die Anzahl der Bilder nicht ohne Rest mit der Anzahl der Zeitfenster teilbar sein, werden die
überschüssigen Bilder auf die Zeitfenster verteilt. Listing \ref{lst:cocd_mapping} zeigt die Abbildung, die in der Implementierung verwendet wird für eine nicht teilbare Anzahl von Frames für
fünf Zeitfenster.
\begin{lstlisting}[label=lst:cocd_mapping,caption={Anzahl der Frames pro Zeitfenster, je nach Rest für genau 5 Zeitfenster.}, escapeinside={(*}{*)}]
Sei X die Anzahl der Frames. Dann ist die Anzahl pro Fenster ohne Rest Y = (*$\lfloor \frac{X}{5} \rfloor$*).
Jedes Zeitfenster enthält für die Reste 0, 1, 2, 3, 4 folgende Anzahl an Frames:
0 => [Y,     Y,     Y,     Y, Y    ]
1 => [Y + 1, Y,     Y,     Y, Y    ]
2 => [Y + 1, Y,     Y,     Y, Y + 1]
3 => [Y + 1, Y,     Y + 1, Y, Y + 1]
4 => [Y + 1, Y + 1, Y + 1, Y, Y + 1]
\end{lstlisting}
Es wurden unterschiedliche Anzahlen an Zeitfenster getestet. Entschieden wurde sich letztlich um fünf Zeitfenster, da einerseits die Berechnung des Features mit zunehmender Zeitfensteranzahl komplexer wird
(Kapitel \ref{sec:eval_speed}) und andererseits zu viele Zeitfenster redundant sein können.
\newline
\newline
Die Schwerpunktverteilung ist durch das Dividieren durch die Gesamthelligkeit $P$ invariant gegenüber Skalierung der Helligkeit, jedoch nicht gegenüber einem Offset. Alternativ kann
die Division durch $P$ weggelassen werden, damit ausschließlich mit Ganzzahlen gerechnet wird. Dadurch können größere Bäume generiert werden, weil ganze Zahlen weniger Speicher benötigen als Fließkommazahlen
(Kapitel \ref{sec:eval_size}), und die Feature-Extrahierung ist schneller (Kapitel \ref{sec:eval_speed}). Die Schwerpunktverteilung
mit Ganzzahlen ist durch das Weglassen der Division durch $P$ invariant gegenüber einen Offset $O$, da $\sum_{i=0}^{2}(q_{i,2} + O) - \sum_{i=0}^{2}(q_{i,0} + O)\ =\ \sum_{i=0}^{2} q_{i,2} - \sum_{i=0}^{2} q_{i,0} = X_Q$
ist und analog für $Y_Q$. Der Ansatz mit den Ganzzahlen konstruiert Schwerpunkte in $[-3069, 3069]^2$, da Sensorenwerte in $[0, 1023]$ liegen, und der Ansatz mit Gleitkommazahlen konstruiert
Schwerpunkte in $[-1, 1]^2$, da mit der Gesamthelligkeit $P$ normalisiert wurde.
